"""
åˆ†å¸ƒå¼ GAN è®­ç»ƒï¼ˆæœ€ç»ˆç¨³å®šç‰ˆï¼‰
- ä¸å†ä½¿ç”¨å…±äº«å†…å­˜ä¼ æ¨¡å‹å‚æ•°ï¼ˆé¿å… data_region fullï¼‰
- å‚æ•°åŒæ­¥åŸºäº RPCï¼ˆget_weights / set_weightsï¼‰
- å‚æ•°é¡ºåºå›ºå®šä¸º sorted(key)
- æ”¯æŒæµ®ç‚¹å‚æ•°å¹³å‡ï¼Œæ•´æ•°/å¸ƒå°”å‚æ•°ç›´æ¥å– worker0
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Subset

import numpy as np
import time
import os
import sys

# æ·»åŠ  miniray python è·¯å¾„
_current_dir = os.path.dirname(os.path.abspath(__file__))
_python_path = os.path.join(_current_dir, '..', 'python')
if _python_path not in sys.path:
    sys.path.insert(0, _python_path)

import miniray
from ml.gan_cifar10 import Generator, Discriminator


# ============================================================
# Workerï¼šè®­ç»ƒå•ä¸ª shard çš„ GAN
# ============================================================

@miniray.remote
class DistributedGANWorker:
    def __init__(self, worker_id, latent_dim=100, lr=0.0002, device=None):
        self.worker_id = worker_id
        self.latent_dim = latent_dim
        self.lr = lr
        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')

        print(f"[Worker {worker_id}] åˆå§‹åŒ– - è®¾å¤‡: {self.device}")

        self.generator = Generator(latent_dim).to(self.device)
        self.discriminator = Discriminator().to(self.device)

        self.optimizer_G = optim.Adam(self.generator.parameters(), lr=lr, betas=(0.5, 0.999))
        self.optimizer_D = optim.Adam(self.discriminator.parameters(), lr=lr, betas=(0.5, 0.999))

        self.criterion = nn.BCELoss()
        self.dataloader = None

    def load_data_shard(self, shard_id, num_shards, batch_size=128, dataset_root='./data'):
        """åŠ è½½åˆ†ç‰‡æ•°æ®"""
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])

        full_dataset = torchvision.datasets.CIFAR10(
            root=dataset_root,
            train=True,
            download=False,
            transform=transform
        )

        total_size = len(full_dataset)
        per_shard = total_size // num_shards
        start = shard_id * per_shard
        end = (start + per_shard) if shard_id < num_shards - 1 else total_size

        subset = Subset(full_dataset, list(range(start, end)))

        self.dataloader = DataLoader(subset, batch_size=batch_size, shuffle=True, num_workers=0)

        print(f"[Worker {self.worker_id}] æ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(subset)} å¼ å›¾åƒ")

    def train_epoch(self, epoch):
        """è®­ç»ƒä¸€ä¸ª epoch"""
        g_loss_total = 0
        d_loss_total = 0
        batches = 0

        for real_images, _ in self.dataloader:
            real_images = real_images.to(self.device)
            bsz = real_images.size(0)

            real_labels = torch.ones(bsz, 1).to(self.device)
            fake_labels = torch.zeros(bsz, 1).to(self.device)

            # ----------- train D ----------------
            self.optimizer_D.zero_grad()

            out_real = self.discriminator(real_images)
            loss_real = self.criterion(out_real, real_labels)

            z = torch.randn(bsz, self.latent_dim).to(self.device)
            fake_imgs = self.generator(z)
            out_fake = self.discriminator(fake_imgs.detach())
            loss_fake = self.criterion(out_fake, fake_labels)

            d_loss = loss_real + loss_fake
            d_loss.backward()
            self.optimizer_D.step()

            # ----------- train G ----------------
            self.optimizer_G.zero_grad()

            z = torch.randn(bsz, self.latent_dim).to(self.device)
            fake_imgs = self.generator(z)
            out_fake = self.discriminator(fake_imgs)
            g_loss = self.criterion(out_fake, real_labels)
            g_loss.backward()
            self.optimizer_G.step()

            g_loss_total += g_loss.item()
            d_loss_total += d_loss.item()
            batches += 1

        return {
            "worker_id": self.worker_id,
            "epoch": epoch,
            "g_loss": g_loss_total / batches,
            "d_loss": d_loss_total / batches,
        }

    # ======================================================
    # å‚æ•°åŒæ­¥æ¥å£ï¼ˆæœ€ç»ˆä¿®æ­£ç‰ˆï¼‰
    # ======================================================

    def get_weights(self):
        """æŒ‰æ’åºé¡ºåºè¿”å›æ¨¡å‹å‚æ•°ï¼ˆTensor åˆ—è¡¨ï¼‰"""
        weights = []

        # generator
        gen_sd = self.generator.state_dict()
        for key in sorted(gen_sd.keys()):
            weights.append(gen_sd[key].detach().cpu())

        # discriminator
        disc_sd = self.discriminator.state_dict()
        for key in sorted(disc_sd.keys()):
            weights.append(disc_sd[key].detach().cpu())

        return weights

    def set_weights(self, weights):
        """æŒ‰ç›¸åŒé¡ºåºæ¢å¤å‚æ•°"""
        idx = 0

        gen_sd = self.generator.state_dict()
        for key in sorted(gen_sd.keys()):
            gen_sd[key] = weights[idx].to(self.device)
            idx += 1
        self.generator.load_state_dict(gen_sd)

        disc_sd = self.discriminator.state_dict()
        for key in sorted(disc_sd.keys()):
            disc_sd[key] = weights[idx].to(self.device)
            idx += 1
        self.discriminator.load_state_dict(disc_sd)

    def save_models(self, path):
        os.makedirs(path, exist_ok=True)
        torch.save(self.generator.state_dict(), f"{path}/generator_{self.worker_id}.pth")
        torch.save(self.discriminator.state_dict(), f"{path}/discriminator_{self.worker_id}.pth")
        return f"[Worker {self.worker_id}] æ¨¡å‹å·²ä¿å­˜"


# ============================================================
# Trainerï¼šè´Ÿè´£è°ƒåº¦å¤šä¸ª Worker
# ============================================================

class DistributedGANTrainer:
    def __init__(self, num_workers=4, latent_dim=100, lr=0.0002):
        self.num_workers = num_workers
        self.latent_dim = latent_dim
        self.lr = lr

    def train(self, epochs=50, batch_size=128, sync_interval=20):
        print("========== å¯åŠ¨ Mini-Ray ==========")
        miniray.init(num_workers=self.num_workers)

        print("========== å¯åŠ¨ Workers ==========")
        workers = []
        for i in range(self.num_workers):
            w = DistributedGANWorker.remote(i, self.latent_dim, self.lr)
            workers.append(w)

        print("========== åŠ è½½åˆ†å¸ƒå¼æ•°æ® ==========")
        refs = [w.load_data_shard.remote(i, self.num_workers, batch_size) for i, w in enumerate(workers)]
        miniray.get(refs)

        history = []

        # ===========================
        # ä¸»è®­ç»ƒå¾ªç¯
        # ===========================
        for epoch in range(epochs):
            print(f"\n===== Epoch {epoch+1}/{epochs} =====")

            # 1) å¹¶è¡Œè®­ç»ƒ
            train_refs = [w.train_epoch.remote(epoch) for w in workers]
            results = miniray.get(train_refs)

            g_loss = np.mean([r["g_loss"] for r in results])
            d_loss = np.mean([r["d_loss"] for r in results])
            print(f"[Epoch {epoch+1}] G_loss={g_loss:.4f}  D_loss={d_loss:.4f}")

            history.append((g_loss, d_loss))

            # 2) å‚æ•°åŒæ­¥
            if (epoch + 1) % sync_interval == 0:
                print("ğŸ”„ åŒæ­¥å‚æ•°ä¸­...")

                # RPC è·å–æ‰€æœ‰ worker æƒé‡
                w_lists = miniray.get([w.get_weights.remote() for w in workers])

                num_params = len(w_lists[0])
                avg_weights = []

                # å¹³å‡å‚æ•°ï¼ˆå¤„ç† dtypeï¼‰
                for p in range(num_params):
                    tensors = [w_lists[w][p] for w in range(self.num_workers)]
                    t0 = tensors[0]

                    if torch.is_floating_point(t0):
                        avg = torch.stack(tensors).mean(0)
                    else:
                        avg = t0  # int/bool ä¸èƒ½å¹³å‡

                    avg_weights.append(avg)

                # å¹¿æ’­å¹³å‡å‚æ•°
                miniray.get([w.set_weights.remote(avg_weights) for w in workers])
                print("âœ… å‚æ•°åŒæ­¥å®Œæˆ")

        print("\n===== è®­ç»ƒç»“æŸ =====")
        return history, workers

# ============================================================
# åˆ†å¸ƒå¼å›¾ç‰‡ç”Ÿæˆ Worker
# ============================================================

@miniray.remote
class DistributedImageGenerator:
    """
    è´Ÿè´£åŠ è½½ Generator å¹¶ç”Ÿæˆå›¾ç‰‡
    """
    def __init__(self, worker_id, latent_dim=100, device=None):
        self.worker_id = worker_id
        self.latent_dim = latent_dim
        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')
        self.generator = None
        print(f"[GenWorker {worker_id}] åˆå§‹åŒ– - è®¾å¤‡: {self.device}")

    def load_model(self, model_path):
        """åŠ è½½è®­ç»ƒå¥½çš„ Generator æ¨¡å‹"""
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"æ¨¡å‹ä¸å­˜åœ¨: {model_path}")

        self.generator = Generator(self.latent_dim).to(self.device)
        self.generator.load_state_dict(torch.load(model_path, map_location=self.device))
        self.generator.eval()
        return f"[GenWorker {self.worker_id}] æ¨¡å‹åŠ è½½å®Œæˆ"

    def generate_images(self, num_images, seed=None):
        """ç”Ÿæˆæ‰¹é‡å›¾ç‰‡å¹¶è¿”å› numpy æ•°ç»„"""
        if self.generator is None:
            raise RuntimeError("Generator æœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨ load_model()")

        if seed is not None:
            torch.manual_seed(seed + self.worker_id)
            np.random.seed(seed + self.worker_id)

        with torch.no_grad():
            z = torch.randn(num_images, self.latent_dim).to(self.device)
            fake = self.generator(z)

            # (N, C, H, W) â†’ (N, H, W, C)
            imgs = fake.cpu().numpy()
            imgs = np.transpose(imgs, (0, 2, 3, 1))

            # åå½’ä¸€åŒ– [-1,1] â†’ [0,1]
            imgs = (imgs + 1) / 2.0
            imgs = np.clip(imgs, 0, 1)

            return imgs


# ============================================================
# åˆ†å¸ƒå¼å›¾ç‰‡ç”Ÿæˆåè°ƒå™¨ï¼ˆå¯ç‹¬ç«‹ä½¿ç”¨ï¼‰
# ============================================================

class DistributedImageGeneratorCoordinator:
    """
    æ§åˆ¶å¤šä¸ª Worker å¹¶è¡Œç”Ÿæˆå¤§é‡å›¾ç‰‡
    """

    def __init__(self, num_workers=4, latent_dim=100):
        self.num_workers = num_workers
        self.latent_dim = latent_dim

    def generate(self, model_path, total_images=100, save_dir="./generated_images", seed=42):
        print("\n====================== åˆ†å¸ƒå¼å›¾ç‰‡ç”Ÿæˆ ======================")
        print(f"æ¨¡å‹: {model_path}")
        print(f"æ€»å›¾ç‰‡æ•°: {total_images}")
        print(f"Workers: {self.num_workers}")

        # åˆå§‹åŒ– Mini-Ray
        if not hasattr(miniray, "_initialized") or not miniray._initialized:
            miniray.init(num_workers=self.num_workers)
            print(f"Mini-Ray å·²åˆå§‹åŒ– ({self.num_workers} workers)")

        # å¯åŠ¨ Workers
        workers = [
            DistributedImageGenerator.remote(i, self.latent_dim)
            for i in range(self.num_workers)
        ]

        # åŠ è½½æ¨¡å‹
        print("ğŸ“¦ åŠ è½½æ¨¡å‹åˆ° Workers ...")
        load_refs = [w.load_model.remote(model_path) for w in workers]
        msgs = miniray.get(load_refs)
        for msg in msgs:
            print(msg)

        # æ¯ä¸ª worker çš„ç”Ÿæˆæ•°é‡
        base = total_images // self.num_workers
        extra = total_images % self.num_workers

        gen_refs = []
        for i, w in enumerate(workers):
            n = base + (extra if i == self.num_workers - 1 else 0)
            ref = w.generate_images.remote(n, seed=seed)
            gen_refs.append(ref)

        print("ğŸ¨ æ­£åœ¨ç”Ÿæˆå›¾ç‰‡ ...")
        batches = miniray.get(gen_refs)

        # åˆå¹¶æ‰€æœ‰ç»“æœ
        imgs = np.concatenate(batches, axis=0)
        print(f"ç”Ÿæˆå®Œæˆ: {imgs.shape[0]} å¼ ")

        # ä¿å­˜å›¾ç‰‡
        os.makedirs(save_dir, exist_ok=True)
        from PIL import Image

        for idx, img in enumerate(imgs):
            pil_img = Image.fromarray((img * 255).astype(np.uint8))
            pil_img.save(f"{save_dir}/generated_{idx:04d}.png")

        print(f"å·²ä¿å­˜åˆ° {save_dir}")
        print("\n====================== å®Œæˆ ======================\n")

        return imgs
