# Mini-Ray Parameter Server

è½»é‡çº§å‚æ•°æœåŠ¡å™¨ï¼Œä½œä¸º Mini-Ray çš„æ ¸å¿ƒèƒ½åŠ›ä¹‹ä¸€ï¼Œç”¨äºåˆ†å¸ƒå¼è®­ç»ƒä¸­çš„å‚æ•°åŒæ­¥ã€‚

## âœ¨ ç‰¹ç‚¹

- âœ… **é€šç”¨**ï¼šæ”¯æŒä»»æ„æ¨¡å‹ï¼ˆGANã€ResNetã€BERT ç­‰ï¼‰
- âœ… **è½»é‡**ï¼š~100 è¡Œä»£ç ï¼Œæ— é¢å¤–ä¾èµ–
- âœ… **å¯æ‰©å±•**ï¼šæ”¯æŒå¤šç§èšåˆç­–ç•¥ï¼ˆå¹³å‡ã€åŠ æƒã€åŠ¨é‡ï¼‰
- âœ… **æ˜“ç”¨**ï¼šä¸€è¡Œä»£ç å®Œæˆå‚æ•°åŒæ­¥
- âœ… **é›†æˆ**ï¼šä½œä¸º Mini-Ray æ ¸å¿ƒæ¨¡å—ï¼Œå¼€ç®±å³ç”¨

## ğŸ“¦ å¿«é€Ÿå¼€å§‹

### åŸºç¡€ç”¨æ³•

```python
import miniray
from miniray.ps import create_parameter_server

# 1. åˆ›å»º ParameterServer
ps = create_parameter_server('average')

# 2. åœ¨è®­ç»ƒå¾ªç¯ä¸­åŒæ­¥å‚æ•°
for epoch in range(epochs):
    # è®­ç»ƒ...
    if (epoch + 1) % sync_interval == 0:
        ps.sync_from_workers.remote(workers)
```

### å®Œæ•´ç¤ºä¾‹

```python
import miniray
from miniray.ps import create_parameter_server
import torch.nn as nn

# å®šä¹‰ Workerï¼ˆéœ€å®ç° get_weights() å’Œ set_weights()ï¼‰
@miniray.remote
class TrainingWorker:
    def __init__(self, worker_id):
        self.model = nn.Linear(10, 1)

    def get_weights(self):
        return [p.detach().cpu() for p in self.model.parameters()]

    def set_weights(self, weights):
        with torch.no_grad():
            for param, new_weight in zip(self.model.parameters(), weights):
                param.copy_(new_weight)

    def train_step(self):
        # è®­ç»ƒé€»è¾‘...
        pass

# åˆå§‹åŒ– Mini-Ray
miniray.init(num_workers=4)

# åˆ›å»º ParameterServer å’Œ Workers
ps = create_parameter_server('average')
workers = [TrainingWorker.remote(i) for i in range(4)]

# è®­ç»ƒå¾ªç¯
for epoch in range(10):
    # å¹¶è¡Œè®­ç»ƒ
    miniray.get([w.train_step.remote() for w in workers])

    # æ¯ 3 ä¸ª epoch åŒæ­¥ä¸€æ¬¡
    if (epoch + 1) % 3 == 0:
        ps.sync_from_workers.remote(workers)
        print(f"Epoch {epoch+1}: å‚æ•°åŒæ­¥å®Œæˆ")
```

## ğŸ¯ èšåˆç­–ç•¥

### 1. å¹³å‡ç­–ç•¥ï¼ˆé»˜è®¤ï¼‰

```python
ps = create_parameter_server('average')
```

- ç®€å•å¹³å‡æ‰€æœ‰ Worker çš„å‚æ•°
- é€‚ç”¨äºæ•°æ®å‡åŒ€åˆ†å¸ƒçš„åœºæ™¯
- **æœ€å¸¸ç”¨**

### 2. åŠ æƒå¹³å‡ç­–ç•¥

```python
ps = create_parameter_server('weighted')

# è®¾ç½®å„ Worker çš„æƒé‡ï¼ˆå¦‚æ ·æœ¬æ•°é‡ï¼‰
miniray.get(ps.set_worker_weight.remote(0, 1000))
miniray.get(ps.set_worker_weight.remote(1, 2000))
```

- æŒ‰æ ·æœ¬æ•°é‡åŠ æƒå¹³å‡
- é€‚ç”¨äºæ•°æ®ä¸å‡åŒ€åˆ†å¸ƒçš„åœºæ™¯

### 3. åŠ¨é‡ç­–ç•¥

```python
ps = create_parameter_server('momentum', momentum=0.9)
```

- ä½¿ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆEMAï¼‰èšåˆå‚æ•°
- é€‚ç”¨äºéœ€è¦å¹³æ»‘æ›´æ–°çš„åœºæ™¯
- å¯å‡å°‘å‚æ•°æ³¢åŠ¨

## ğŸ“š API å‚è€ƒ

### ParameterServer

**ä¸»è¦æ–¹æ³•**ï¼š

```python
# åŒæ­¥å‚æ•°ï¼ˆæœ€å¸¸ç”¨ï¼‰
ps.sync_from_workers.remote(worker_refs)

# è·å–å…¨å±€å‚æ•°
weights = miniray.get(ps.pull_weights.remote())

# è·å–ç»Ÿè®¡ä¿¡æ¯
stats = miniray.get(ps.get_stats.remote())
# è¿”å›: {'version': 10, 'num_syncs': 10, 'strategy': 'AverageStrategy', ...}

# è®¾ç½® Worker æƒé‡ï¼ˆä»…ç”¨äº weighted ç­–ç•¥ï¼‰
ps.set_worker_weight.remote(worker_id, weight)
```

### Worker æ¥å£è¦æ±‚

ä½¿ç”¨ ParameterServer çš„ Worker å¿…é¡»å®ç°ï¼š

```python
@miniray.remote
class MyWorker:
    def get_weights(self) -> List[torch.Tensor]:
        """è¿”å›æ¨¡å‹å‚æ•°åˆ—è¡¨ï¼ˆçº¿æ€§åŒ–ï¼‰"""
        return [p.detach().cpu() for p in self.model.parameters()]

    def set_weights(self, weights: List[torch.Tensor]):
        """ä»å‚æ•°åˆ—è¡¨æ¢å¤æ¨¡å‹å‚æ•°"""
        with torch.no_grad():
            for param, new_weight in zip(self.model.parameters(), weights):
                param.copy_(new_weight.to(self.device))
```

## ğŸ”§ é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰èšåˆç­–ç•¥

```python
from miniray.ps.strategies import SyncStrategy, STRATEGIES

class MedianStrategy(SyncStrategy):
    """ä¸­ä½æ•°ç­–ç•¥ï¼ˆå¯¹å¼‚å¸¸å€¼æ›´é²æ£’ï¼‰"""

    def aggregate(self, weight_lists):
        import torch
        num_params = len(weight_lists[0])
        aggregated = []

        for p_idx in range(num_params):
            tensors = [w[p_idx] for w in weight_lists]
            if torch.is_floating_point(tensors[0]):
                stacked = torch.stack(tensors)
                median_tensor = torch.median(stacked, dim=0)[0]
                aggregated.append(median_tensor)
            else:
                aggregated.append(tensors[0])

        return aggregated

# æ³¨å†Œç­–ç•¥
STRATEGIES['median'] = MedianStrategy

# ä½¿ç”¨
from miniray.ps import create_parameter_server
ps = create_parameter_server('median')
```

### è·å–åŒæ­¥ç»Ÿè®¡

```python
# åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç›‘æ§åŒæ­¥çŠ¶æ€
stats = miniray.get(ps.get_stats.remote())

print(f"å‚æ•°ç‰ˆæœ¬: {stats['version']}")
print(f"åŒæ­¥æ¬¡æ•°: {stats['num_syncs']}")
print(f"èšåˆç­–ç•¥: {stats['strategy']}")
print(f"æ˜¯å¦å·²åˆå§‹åŒ–: {stats['initialized']}")
```

## ğŸ“– ä½¿ç”¨ç¤ºä¾‹

æŸ¥çœ‹å®Œæ•´ç¤ºä¾‹ï¼š

- **åŸºç¡€ç¤ºä¾‹**: `examples/parameter_server_demo.py`
- **GAN è®­ç»ƒ**: `ml/distributed_gan.py`

è¿è¡Œç¤ºä¾‹ï¼š

```bash
# åŸºç¡€ç¤ºä¾‹ï¼ˆæ¼”ç¤ºä¸åŒç­–ç•¥ï¼‰
python examples/parameter_server_demo.py

# GAN è®­ç»ƒç¤ºä¾‹
python -m ml.train --mode distributed --workers 4 --epochs 10
```

## ğŸ¨ æ¶æ„è®¾è®¡

### æ¨¡å—ç»“æ„

```
miniray/ps/
â”œâ”€â”€ __init__.py              # å¯¼å‡ºæ¥å£
â”œâ”€â”€ parameter_server.py      # ParameterServer Actor å®ç°
â”œâ”€â”€ strategies.py            # èšåˆç­–ç•¥
â””â”€â”€ README.md                # æœ¬æ–‡æ¡£
```

### å·¥ä½œæµç¨‹

```
Driver Process
    â”‚
    â”œâ”€ åˆ›å»º ParameterServer Actor
    â”‚
    â”œâ”€ åˆ›å»ºå¤šä¸ª Training Workers
    â”‚
    â””â”€ è®­ç»ƒå¾ªç¯
        â”œâ”€ Workers å¹¶è¡Œè®­ç»ƒ
        â”‚
        â””â”€ å‘¨æœŸæ€§å‚æ•°åŒæ­¥
            â”œâ”€ 1. PS æ”¶é›†æ‰€æœ‰ Worker æƒé‡
            â”œâ”€ 2. PS ä½¿ç”¨ç­–ç•¥èšåˆæƒé‡
            â”œâ”€ 3. PS ä¸‹å‘èšåˆåçš„æƒé‡
            â””â”€ 4. Workers æ›´æ–°æœ¬åœ°å‚æ•°
```

## ğŸ’¡ è®¾è®¡ç†å¿µ

### ä¸ºä»€ä¹ˆéœ€è¦ ParameterServerï¼Ÿ

**é—®é¢˜**ï¼šåˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œæ¯ä¸ªæ–°æ¨¡å‹éƒ½è¦é‡å¤å†™å‚æ•°åŒæ­¥é€»è¾‘ï¼š

```python
# âŒ æ¯æ¬¡éƒ½è¦å†™è¿™äº›ä»£ç 
weight_lists = miniray.get([w.get_weights.remote() for w in workers])
avg_weights = []
for p in range(len(weight_lists[0])):
    tensors = [weight_lists[w][p] for w in range(num_workers)]
    avg_weights.append(torch.stack(tensors).mean(0))
miniray.get([w.set_weights.remote(avg_weights) for w in workers])
```

**è§£å†³æ–¹æ¡ˆ**ï¼šè½»é‡çº§ ParameterServer

```python
# âœ… ä¸€è¡Œæå®š
ps.sync_from_workers.remote(workers)
```

### ä¸ºä»€ä¹ˆæ˜¯è½»é‡çº§ï¼Ÿ

- **ä¸æ˜¯å®Œæ•´çš„ PS ç³»ç»Ÿ**ï¼šæ— éœ€å¤„ç†å¤æ‚çš„åˆ†ç‰‡ã€å®¹é”™ã€ç‰ˆæœ¬ç®¡ç†
- **é€‚åˆå°è§„æ¨¡è®­ç»ƒ**ï¼š4-16 ä¸ª Workersï¼ŒåŒæ­¥é¢‘ç‡ä½
- **ä¿æŒç®€æ´**ï¼šç¬¦åˆ Mini-Ray çš„è®¾è®¡å“²å­¦

## ğŸ”„ ä¸å…¶ä»–æ¡†æ¶å¯¹æ¯”

| ç‰¹æ€§ | Mini-Ray PS | PyTorch DDP | Ray Train |
|------|-------------|-------------|-----------|
| ä»£ç é‡ | ~100 è¡Œ | å†…ç½® | å®Œæ•´æ¡†æ¶ |
| æ˜“ç”¨æ€§ | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ |
| çµæ´»æ€§ | â­â­â­â­ | â­â­ | â­â­â­â­â­ |
| é€‚ç”¨åœºæ™¯ | æ•™è‚²/å°è§„æ¨¡ | ç”Ÿäº§ç¯å¢ƒ | ç”Ÿäº§ç¯å¢ƒ |
| è‡ªå®šä¹‰ç­–ç•¥ | âœ… ç®€å• | âŒ å›°éš¾ | âœ… å¯èƒ½ |

## ğŸ“ˆ æ€§èƒ½è€ƒé‡

### åŒæ­¥å¼€é”€

- **ç½‘ç»œä¼ è¾“**ï¼šWorker â†” ParameterServer
- **åºåˆ—åŒ–å¼€é”€**ï¼šPython â†” å…±äº«å†…å­˜
- **èšåˆè®¡ç®—**ï¼šå–å†³äºç­–ç•¥ï¼ˆå¹³å‡ < åŠ æƒ < åŠ¨é‡ï¼‰

### ä¼˜åŒ–å»ºè®®

1. **é™ä½åŒæ­¥é¢‘ç‡**ï¼š`sync_interval = 5-10`
2. **å‡å°‘ Worker æ•°é‡**ï¼šå»ºè®® â‰¤ CPU æ ¸å¿ƒæ•° / 2
3. **ä½¿ç”¨ç®€å•ç­–ç•¥**ï¼šä¼˜å…ˆé€‰æ‹© `average`

## ğŸš€ æœªæ¥æ‰©å±•

- [ ] æ”¯æŒå¼‚æ­¥å‚æ•°æ›´æ–°ï¼ˆpush/pull æ¨¡å¼ï¼‰
- [ ] æ”¯æŒæ¢¯åº¦èšåˆï¼ˆè€Œéæƒé‡èšåˆï¼‰
- [ ] æ”¯æŒå‚æ•°åˆ†ç‰‡ï¼ˆé’ˆå¯¹å¤§æ¨¡å‹ï¼‰
- [ ] æ”¯æŒå®¹é”™å’Œæ£€æŸ¥ç‚¹
- [ ] æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ

## ğŸ“ å¸¸è§é—®é¢˜

**Q: ä½•æ—¶ä½¿ç”¨ ParameterServerï¼Ÿ**

A: å½“ä½ éœ€è¦åœ¨å¤šä¸ª Worker ä¹‹é—´åŒæ­¥æ¨¡å‹å‚æ•°æ—¶ã€‚é€‚ç”¨äºæ•°æ®å¹¶è¡Œè®­ç»ƒåœºæ™¯ã€‚

**Q: ä¸æ‰‹åŠ¨åŒæ­¥æœ‰ä½•åŒºåˆ«ï¼Ÿ**

A: ParameterServer å°è£…äº†æ”¶é›†ã€èšåˆã€ä¸‹å‘çš„å®Œæ•´æµç¨‹ï¼Œæ”¯æŒå¤šç§ç­–ç•¥ï¼Œä»£ç æ›´ç®€æ´ã€‚

**Q: æ”¯æŒå¼‚æ­¥è®­ç»ƒå—ï¼Ÿ**

A: å½“å‰ç‰ˆæœ¬æ˜¯åŒæ­¥è®­ç»ƒï¼ˆæ‰€æœ‰ Worker åŒæ—¶æ›´æ–°ï¼‰ã€‚å¼‚æ­¥è®­ç»ƒè®¡åˆ’åœ¨æœªæ¥ç‰ˆæœ¬æ”¯æŒã€‚

**Q: å¦‚ä½•é€‰æ‹©èšåˆç­–ç•¥ï¼Ÿ**

A:
- æ•°æ®å‡åŒ€åˆ†å¸ƒ â†’ `average`
- æ•°æ®ä¸å‡åŒ€ â†’ `weighted`
- éœ€è¦å¹³æ»‘æ›´æ–° â†’ `momentum`

**Q: æ€§èƒ½ç“¶é¢ˆåœ¨å“ªï¼Ÿ**

A: ä¸»è¦æ˜¯ç½‘ç»œä¼ è¾“å’Œåºåˆ—åŒ–ã€‚å»ºè®®é™ä½åŒæ­¥é¢‘ç‡ï¼Œæˆ–ä½¿ç”¨æ¢¯åº¦å‹ç¼©ï¼ˆæœªæ¥æ”¯æŒï¼‰ã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®æ–°çš„èšåˆç­–ç•¥æˆ–æ€§èƒ½ä¼˜åŒ–ï¼è¯·å‚è€ƒï¼š

1. ç»§æ‰¿ `SyncStrategy` å®ç°è‡ªå®šä¹‰ç­–ç•¥
2. åœ¨ `STRATEGIES` å­—å…¸ä¸­æ³¨å†Œ
3. ç¼–å†™æµ‹è¯•å’Œæ–‡æ¡£
4. æäº¤ Pull Request

## ğŸ“„ è®¸å¯è¯

MIT License
