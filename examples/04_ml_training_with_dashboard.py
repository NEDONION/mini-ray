#!/usr/bin/env python3
"""
ML è®­ç»ƒå’Œæ¨ç† Demo - Dashboard é›†æˆç‰ˆ

å±•ç¤ºï¼š
1. æ•°æ®å¹¶è¡Œè®­ç»ƒ - å¤šä¸ª worker è®­ç»ƒæ¨¡å‹
2. åˆ†å¸ƒå¼æ‰¹é‡æ¨ç† - å¤šä¸ªæœåŠ¡å™¨å¤„ç†æ¨ç†è¯·æ±‚
3. æ‰€æœ‰ä»»åŠ¡å®æ—¶æ˜¾ç¤ºåœ¨ Dashboard ä¸Š

ä½¿ç”¨æ–¹æ³•:
    1. å…ˆå¯åŠ¨ Dashboard: python examples/test_dashboard_v2.py
    2. åœ¨å¦ä¸€ä¸ªç»ˆç«¯è¿è¡Œæ­¤è„šæœ¬: python examples/04_ml_training_with_dashboard.py
    3. åœ¨æµè§ˆå™¨æŸ¥çœ‹ http://localhost:8266 å®æ—¶ç›‘æ§
"""
import sys
import os
import time
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, os.path.join(PROJECT_ROOT, 'python'))

import miniray
from miniray.dashboard import get_collector


# ============================================================
# Demo 1: æ•°æ®å¹¶è¡Œè®­ç»ƒ
# ============================================================

@miniray.remote
class TrainingWorker:
    """è®­ç»ƒ Worker - åœ¨æœ¬åœ°è®­ç»ƒæ¨¡å‹çš„ä¸€éƒ¨åˆ†"""

    def __init__(self, worker_id, model_name="RandomForest"):
        self.worker_id = worker_id
        self.model_name = model_name
        print(f"[Worker {worker_id}] åˆå§‹åŒ–å®Œæˆ")

    def train(self, X_train, y_train, job_id):
        """è®­ç»ƒæ¨¡å‹"""
        collector = get_collector()

        # è®°å½•è®­ç»ƒå¼€å§‹
        collector.add_training_log(job_id, f"[INFO] Worker {self.worker_id} å¼€å§‹è®­ç»ƒ")

        print(f"[Worker {self.worker_id}] å¼€å§‹è®­ç»ƒï¼Œæ•°æ®é‡: {len(X_train)} æ ·æœ¬")

        # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
        epochs = 10
        for epoch in range(epochs):
            time.sleep(0.5)  # æ¨¡æ‹Ÿè®­ç»ƒæ—¶é—´

            # æ¨¡æ‹Ÿè®­ç»ƒæŒ‡æ ‡
            loss = 2.0 * np.exp(-epoch / 3) + np.random.rand() * 0.1
            accuracy = 1.0 - loss / 2.0

            # æ›´æ–°è¿›åº¦
            progress = (epoch + 1) / epochs * 100
            collector.record_training_job(
                job_id=job_id,
                name=f"{self.model_name} Training",
                status='Running',
                progress=progress,
                config={'model': self.model_name, 'worker': self.worker_id, 'epochs': epochs},
                metrics={'loss': float(loss), 'accuracy': float(accuracy), 'epoch': epoch + 1}
            )

            # æ·»åŠ æ—¥å¿—
            log_msg = f"[INFO] Worker {self.worker_id} | Epoch {epoch+1}/{epochs} | Loss: {loss:.4f} | Acc: {accuracy:.4f}"
            collector.add_training_log(job_id, log_msg)
            print(f"[Worker {self.worker_id}] Epoch {epoch+1}/{epochs} - Loss: {loss:.4f}, Acc: {accuracy:.4f}")

        final_accuracy = accuracy

        # è®­ç»ƒå®Œæˆ
        collector.record_training_job(
            job_id=job_id,
            name=f"{self.model_name} Training",
            status='Completed',
            progress=100.0,
            config={'model': self.model_name, 'worker': self.worker_id, 'epochs': epochs},
            metrics={'loss': float(loss), 'accuracy': float(final_accuracy)}
        )
        collector.add_training_log(job_id, f"[SUCCESS] Worker {self.worker_id} è®­ç»ƒå®Œæˆï¼æœ€ç»ˆå‡†ç¡®ç‡: {final_accuracy:.4f}")

        print(f"[Worker {self.worker_id}] è®­ç»ƒå®Œæˆï¼æœ€ç»ˆå‡†ç¡®ç‡: {final_accuracy:.4f}")

        return {
            'worker_id': self.worker_id,
            'accuracy': float(final_accuracy),
            'loss': float(loss)
        }


def demo1_data_parallel_training():
    """Demo 1: æ•°æ®å¹¶è¡Œè®­ç»ƒ"""
    print("\n" + "="*70)
    print("  Demo 1: æ•°æ®å¹¶è¡Œè®­ç»ƒ")
    print("="*70 + "\n")

    collector = get_collector()
    job_id = f"job-dp-{int(time.time())}"

    # åˆ›å»ºè®­ç»ƒä»»åŠ¡è®°å½•
    collector.record_training_job(
        job_id=job_id,
        name="Data Parallel Training",
        status='Pending',
        progress=0.0,
        config={'model': 'RandomForest', 'workers': 3, 'strategy': 'data_parallel'},
        metrics={}
    )
    collector.add_training_log(job_id, "[INFO] æ•°æ®å¹¶è¡Œè®­ç»ƒä»»åŠ¡å·²åˆ›å»º")

    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    print("ğŸ“Š ç”Ÿæˆè®­ç»ƒæ•°æ®...")
    n_samples = 3000
    n_features = 20
    X = np.random.randn(n_samples, n_features)
    y = (X.sum(axis=1) > 0).astype(int)

    # å°†æ•°æ®åˆ†æˆ 3 ä»½
    n_workers = 3
    chunk_size = n_samples // n_workers

    print(f"ğŸ“¦ å°†æ•°æ®åˆ†æˆ {n_workers} ä»½ï¼Œæ¯ä»½ {chunk_size} æ ·æœ¬")
    print(f"ğŸš€ å¯åŠ¨ {n_workers} ä¸ªè®­ç»ƒ Worker...")
    collector.add_training_log(job_id, f"[INFO] å¯åŠ¨ {n_workers} ä¸ª Worker è¿›è¡Œå¹¶è¡Œè®­ç»ƒ")

    # åˆ›å»º Worker
    workers = [TrainingWorker.remote(i, "RandomForest") for i in range(n_workers)]

    # åˆ†å‘æ•°æ®å¹¶è¡Œè®­ç»ƒ
    train_refs = []
    for i, worker in enumerate(workers):
        start_idx = i * chunk_size
        end_idx = start_idx + chunk_size
        X_chunk = X[start_idx:end_idx]
        y_chunk = y[start_idx:end_idx]

        ref = worker.train.remote(X_chunk, y_chunk, job_id)
        train_refs.append(ref)

    # è·å–è®­ç»ƒç»“æœ
    print("\nâ³ ç­‰å¾…æ‰€æœ‰ Worker å®Œæˆè®­ç»ƒ...\n")
    results = miniray.get(train_refs)

    # èšåˆç»“æœ
    avg_accuracy = np.mean([r['accuracy'] for r in results])
    print(f"\nâœ… æ‰€æœ‰ Worker è®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“ˆ å¹³å‡å‡†ç¡®ç‡: {avg_accuracy:.4f}")

    worker_acc_list = [f"{r['accuracy']:.4f}" for r in results]
    print(f"ğŸ“Š å„ Worker å‡†ç¡®ç‡: {worker_acc_list}")

    collector.add_training_log(job_id, f"[SUCCESS] è®­ç»ƒå®Œæˆï¼å¹³å‡å‡†ç¡®ç‡: {avg_accuracy:.4f}")

    return results


# ============================================================
# Demo 2: åˆ†å¸ƒå¼æ‰¹é‡æ¨ç†
# ============================================================

@miniray.remote
class InferenceServer:
    """æ¨ç†æœåŠ¡å™¨"""

    def __init__(self, server_id, model_name="Classifier"):
        self.server_id = server_id
        self.model_name = model_name
        self.request_count = 0
        print(f"[Server {server_id}] æ¨ç†æœåŠ¡å™¨å¯åŠ¨")

    def predict(self, X_batch, service_id):
        """æ‰¹é‡æ¨ç†"""
        collector = get_collector()

        batch_size = len(X_batch)
        self.request_count += batch_size

        # æ¨¡æ‹Ÿæ¨ç†æ—¶é—´
        start_time = time.time()
        time.sleep(0.1)  # æ¨¡æ‹Ÿæ¨ç†å»¶è¿Ÿ

        # ç”Ÿæˆæ¨¡æ‹Ÿé¢„æµ‹ç»“æœ
        predictions = (X_batch.sum(axis=1) > 0).astype(int)

        latency = (time.time() - start_time) * 1000  # ms

        # æ›´æ–°æœåŠ¡ç»Ÿè®¡
        collector.record_inference_service(
            service_id=service_id,
            name=f"Inference Server {self.server_id}",
            status='Online',
            model_name=self.model_name,
            endpoint=f"http://server-{self.server_id}:8000",
            config={'server_id': self.server_id, 'model': self.model_name},
            stats={'requests': self.request_count, 'avg_latency': latency}
        )

        print(f"[Server {self.server_id}] å¤„ç† {batch_size} ä¸ªè¯·æ±‚ï¼Œå»¶è¿Ÿ: {latency:.1f}ms")

        return predictions


def demo2_distributed_inference():
    """Demo 2: åˆ†å¸ƒå¼æ‰¹é‡æ¨ç†"""
    print("\n" + "="*70)
    print("  Demo 2: åˆ†å¸ƒå¼æ‰¹é‡æ¨ç†")
    print("="*70 + "\n")

    collector = get_collector()

    # ç”Ÿæˆæ¨ç†æ•°æ®
    print("ğŸ“Š ç”Ÿæˆæ¨ç†æ•°æ®...")
    n_samples = 1000
    n_features = 20
    X = np.random.randn(n_samples, n_features)

    # åˆ›å»ºæ¨ç†æœåŠ¡å™¨
    n_servers = 3
    print(f"ğŸš€ å¯åŠ¨ {n_servers} ä¸ªæ¨ç†æœåŠ¡å™¨...")

    servers = []
    for i in range(n_servers):
        server = InferenceServer.remote(i, "Classifier")
        servers.append(server)

        # æ³¨å†ŒæœåŠ¡
        service_id = f"svc-{i}"
        collector.record_inference_service(
            service_id=service_id,
            name=f"Inference Server {i}",
            status='Online',
            model_name="Classifier",
            endpoint=f"http://server-{i}:8000",
            config={'server_id': i, 'replicas': 1},
            stats={'requests': 0, 'avg_latency': 0}
        )

    # åˆ†å‘æ¨ç†ä»»åŠ¡
    batch_size = n_samples // n_servers
    print(f"ğŸ“¦ å°†æ•°æ®åˆ†æˆ {n_servers} æ‰¹ï¼Œæ¯æ‰¹ {batch_size} æ ·æœ¬")
    print(f"\nâ³ å¼€å§‹åˆ†å¸ƒå¼æ¨ç†...\n")

    predict_refs = []
    for i, server in enumerate(servers):
        start_idx = i * batch_size
        end_idx = start_idx + batch_size
        X_batch = X[start_idx:end_idx]

        ref = server.predict.remote(X_batch, f"svc-{i}")
        predict_refs.append(ref)

    # è·å–æ¨ç†ç»“æœ
    predictions_list = miniray.get(predict_refs)
    all_predictions = np.concatenate(predictions_list)

    print(f"\nâœ… æ¨ç†å®Œæˆï¼")
    print(f"ğŸ“Š å¤„ç†æ ·æœ¬æ•°: {len(all_predictions)}")
    print(f"ğŸ“ˆ é¢„æµ‹åˆ†å¸ƒ: {np.bincount(all_predictions)}")

    return all_predictions


# ============================================================
# ä¸»å‡½æ•°
# ============================================================

def main():
    print("\n" + "="*70)
    print("  Mini-Ray ML Training & Inference Demo")
    print("  with Dashboard Integration")
    print("="*70)

    print("\nğŸ’¡ æç¤º:")
    print("  1. ç¡®ä¿ Dashboard å·²å¯åŠ¨: http://localhost:8266")
    print("  2. åœ¨ Dashboard çš„ Training Jobs é¡µé¢å¯ä»¥çœ‹åˆ°è®­ç»ƒè¿›åº¦")
    print("  3. åœ¨ Inference é¡µé¢å¯ä»¥çœ‹åˆ°æ¨ç†æœåŠ¡")
    print()

    # åˆå§‹åŒ– Mini-Ray
    print("ğŸ”§ åˆå§‹åŒ– Mini-Ray...")
    miniray.init(num_workers=4)
    time.sleep(1)

    collector = get_collector()

    # æ³¨å†Œ Workers
    for i in range(4):
        collector.update_worker(i, 'IDLE')

    # æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
    collector.collect_system_metrics()

    try:
        # Demo 1: æ•°æ®å¹¶è¡Œè®­ç»ƒ
        demo1_data_parallel_training()

        time.sleep(2)

        # Demo 2: åˆ†å¸ƒå¼æ¨ç†
        demo2_distributed_inference()

        print("\n" + "="*70)
        print("  âœ… æ‰€æœ‰ Demo å®Œæˆï¼")
        print("="*70)
        print("\nğŸ’¡ åœ¨ Dashboard æŸ¥çœ‹æ‰€æœ‰è®­ç»ƒä»»åŠ¡å’Œæ¨ç†æœåŠ¡:")
        print("   http://localhost:8266")
        print()

    finally:
        print("\nğŸ”§ å…³é—­ Mini-Ray...")
        miniray.shutdown()
        print("âœ… Demo ç»“æŸ\n")


if __name__ == "__main__":
    main()
